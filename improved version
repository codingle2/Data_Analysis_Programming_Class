"""
Update Summary â€“ Improved Visualization & Modeling Integration

This version includes several enhancements aimed at producing more meaningful visual outputs
and improving the interpretability of the model results for reporting and presentation:

1. Added technical indicators (RSI, MACD, Bollinger Bands, Stochastic, Volume Ratio)
   â†’ Provides richer feature context and more realistic trading signals.

2. Improved handling of imbalanced classes using class_weight='balanced'
   â†’ Prevents the model from predicting only one class (e.g., constant "0" in down-trending markets).

3. Implemented automatic threshold optimization for RandomForest
   â†’ Instead of using a fixed threshold (e.g., 0.55), the model now selects the best threshold
     based on training performance (F1-score), resulting in more reasonable buy/sell signals.

4. Enhanced visualization layer for dashboard/report
   â†’ Clearer price charts, buy/sell markers, NAV comparison, and model metric summaries.

5. Code structure remains compatible with the original pipeline
   â†’ All improvements integrate smoothly without changing team responsibilities or workflow.

These updates make the analysis output more insightful and the final dashboard suitable for
presentation and evaluation.
"""

# ==========================================
# Stock Project Unified Pipeline (Improved)
# ==========================================

import os
import time
import json
import re
import glob
import datetime
import warnings

import numpy as np
import pandas as pd
import requests
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score

# optional XGBoost
try:
    from xgboost import XGBClassifier
    _HAS_XGB = True
except Exception:
    _HAS_XGB = False

warnings.filterwarnings("ignore")

# ==========================================
# 1. ê³µí†µ ìƒìˆ˜ / ìœ í‹¸ í•¨ìˆ˜
# ==========================================

def parse_krw_hangeul(value):
    """
    ê±°ë˜ëŒ€ê¸ˆ(ì–µ) ë‹¨ìœ„ì˜ í•œê¸€ í‘œí˜„ì„ ì •ìˆ˜(ì› ë‹¨ìœ„)ë¡œ ë³€í™˜.
    ì˜ˆ: "1,234ì–µì›" -> 123400000000
    """
    if value is None:
        return 0
    value = str(value).replace(',', '').replace(' ', '')
    if value.endswith('ì–µì›'):
        try:
            num = float(value.replace('ì–µì›', ''))
            return int(num * 100000000)
        except ValueError:
            return 0
    try:
        return int(value)
    except ValueError:
        return 0

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    ),
    "Accept": "application/json, text/plain, */*",
    "Referer": "https://m.stock.naver.com/",
    "Origin": "https://m.stock.naver.com",
}

def clean_value(value):
    """
    API ê°’ì—ì„œ 'ë°°', 'ì›', 'ì–µì›', ',' ë“±ì„ ì œê±°í•´
    ìˆ«ìë§Œ ë‚¨ê¸°ê±°ë‚˜ ê¹”ë”í•œ ë¬¸ìì—´ë¡œ ì •ë¦¬.
    """
    if value is None or value == "":
        return "N/A"
    return (
        str(value)
        .replace('ë°°', '')
        .replace('ì›', '')
        .replace('ì–µì›', '')
        .replace(',', '')
        .strip()
    )

# ==========================================
# 2. ê±°ë˜ëŸ‰ ìƒìœ„ ì¢…ëª© / KOSPI ì§€ìˆ˜
# ==========================================

def get_top_stocks_data(pages=2, page_size=20):
    """
    ë„¤ì´ë²„ ê¸ˆìœµ APIì—ì„œ ê±°ë˜ëŸ‰ ìƒìœ„ ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ DataFrameìœ¼ë¡œ ë°˜í™˜.
    """
    base_api_url = "https://m.stock.naver.com/api/stocks/quantTop/all"
    fetched_data = []

    print(f"=== ìƒìœ„ ì£¼ì‹ ë°ì´í„° í¬ë¡¤ë§ ì‹œì‘ (ì´ {pages * page_size}ê°œ ëª©í‘œ) ===")

    for i in range(1, pages + 1):
        full_url = f"{base_api_url}?page={i}&pageSize={page_size}"
        print(f" -> í˜ì´ì§€ {i} ìš”ì²­ ì¤‘...")

        try:
            response = requests.get(full_url, headers=HEADERS, timeout=5)
            response.raise_for_status()
            data = response.json()

            if isinstance(data, dict) and 'stocks' in data and isinstance(data['stocks'], list):
                fetched_data.extend(data['stocks'])
            else:
                print(f" -> í˜ì´ì§€ {i} ë°ì´í„° ì—†ìŒ í˜¹ì€ í˜•ì‹ ì˜¤ë¥˜.")
                break
        except Exception as e:
            print(f" -> í˜ì´ì§€ {i} ì˜¤ë¥˜ ë°œìƒ: {e}")
            break

        time.sleep(0.1)  # ì„œë²„ ë¶€í•˜ ë°©ì§€ìš© ë”œë ˆì´

    if not fetched_data:
        print("ê±°ë˜ëŸ‰ ìƒìœ„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    df = pd.DataFrame(fetched_data)
    cols = {
        'itemCode': 'ì¢…ëª©ì½”ë“œ',
        'stockName': 'ì¢…ëª©ëª…',
        'closePrice': 'í˜„ì¬ê°€',
        'fluctuationsRatio': 'ë“±ë½ë¥ ',
        'accumulatedTradingVolume': 'ê±°ë˜ëŸ‰',
        'accumulatedTradingValueKrwHangeul': 'ê±°ë˜ëŒ€ê¸ˆ',
    }
    available_cols = [c for c in cols.keys() if c in df.columns]
    df = df[available_cols].rename(columns=cols)

    if 'ê±°ë˜ëŒ€ê¸ˆ' in df.columns:
        df['ê±°ë˜ëŒ€ê¸ˆ'] = df['ê±°ë˜ëŒ€ê¸ˆ'].apply(parse_krw_hangeul)

    return df

def get_kospi_info():
    """
    ë„¤ì´ë²„ì—ì„œ KOSPI ê¸°ë³¸ ì •ë³´ ë° ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¨ë‹¤.
    ë°˜í™˜ê°’: {'basic': ..., 'realtime': ...}
    """
    basic_url = "https://m.stock.naver.com/api/index/KOSPI/basic"
    realtime_url = "https://polling.finance.naver.com/api/realtime/domestic/index/KOSPI"

    result = {}

    try:
        res = requests.get(basic_url, headers=HEADERS, timeout=5)
        res.raise_for_status()
        result['basic'] = res.json()
    except Exception as e:
        print(f"KOSPI ê¸°ë³¸ ì •ë³´ ì˜¤ë¥˜: {e}")
        result['basic'] = None

    try:
        res = requests.get(realtime_url, headers=HEADERS, timeout=5)
        res.raise_for_status()
        data = res.json()
        result['realtime'] = data.get('result', data)
    except Exception as e:
        print(f"KOSPI ì‹¤ì‹œê°„ ì •ë³´ ì˜¤ë¥˜: {e}")
        result['realtime'] = None

    return result

def print_kospi_formatted(kospi_data):
    basic = kospi_data.get('basic')
    if not basic:
        print("KOSPI ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    name = basic.get('stockName', 'KOSPI')
    price = basic.get('closePrice', 'N/A')
    change = basic.get('compareToPreviousClosePrice', '0')
    ratio = basic.get('fluctuationsRatio', '0')

    direction_info = basic.get('compareToPreviousPrice', {})
    direction_text = direction_info.get('text', '')
    symbol = " "
    if direction_text == 'ìƒìŠ¹':
        symbol = "â–²"
    elif direction_text == 'í•˜ë½':
        symbol = "â–¼"

    exchange_info = basic.get('stockExchangeType', {})
    nation = exchange_info.get('nationName', 'KR')
    ex_name = exchange_info.get('nameKor', 'ì½”ìŠ¤í”¼')

    time_str = basic.get('localTradedAt', '')
    if 'T' in time_str:
        time_str = time_str.split('+')[0].replace('T', ' ')

    charts = basic.get('imageCharts', {})
    day_chart = charts.get('day', 'ì •ë³´ ì—†ìŒ')

    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print(f"â”‚  ğŸ‡°ğŸ‡·  [{nation}] {ex_name} ({name}) ìƒì„¸ í˜„í™©      â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(f"â”‚  í˜„ì¬ì§€ìˆ˜  : {price:<33} â”‚")
    print(f"â”‚  ë“±ë½ë¥     : {symbol} {change} ({ratio}%) {direction_text:<15} â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print(f"â”‚  ì¥ ìƒíƒœ   : {basic.get('marketStatus')}                          â”‚")
    print(f"â”‚  ê¸°ì¤€ì‹œê°„  : {time_str:<26}  â”‚")
    print(f"â”‚  ê±°ë˜ì†Œ    : {exchange_info.get('nameEng')} ({exchange_info.get('code')})              â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("â”‚  ğŸ“Š ì¼ë´‰ ì°¨íŠ¸ (í´ë¦­í•˜ì—¬ ë³´ê¸°):                   â”‚")
    print(f"â”‚  {day_chart:<46}  â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

# ==========================================
# 3. ì¢…ëª©ì½”ë“œ / ì¼ë³„ ì‹œì„¸
# ==========================================

def get_code_from_excel(stock_name, file_name='stockCodeInfo.xlsx'):
    """
    ë¡œì»¬ ì—‘ì…€ íŒŒì¼ì—ì„œ 'íšŒì‚¬ëª…'ìœ¼ë¡œ ì¢…ëª©ì½”ë“œë¥¼ ì°¾ëŠ”ë‹¤.
    - ì¢…ëª©ì½”ë“œëŠ” 0ìœ¼ë¡œ ì‹œì‘í•˜ë¯€ë¡œ ë¬¸ìì—´(str)ë¡œ ì½ì–´ì•¼ í•œë‹¤.
    """
    if not os.path.exists(file_name):
        print(f"ì˜¤ë¥˜: '{file_name}' íŒŒì¼ì´ í˜„ì¬ í´ë”ì— ì—†ìŠµë‹ˆë‹¤.")
        return None

    try:
        df = pd.read_excel(file_name, dtype={'ì¢…ëª©ì½”ë“œ': str})
        found_row = df[df['íšŒì‚¬ëª…'] == stock_name]
        if not found_row.empty:
            return str(found_row.iloc[0]['ì¢…ëª©ì½”ë“œ'])
        print(f"'{stock_name}'ì„(ë¥¼) ì—‘ì…€ íŒŒì¼ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    except Exception as e:
        print(f"ì—‘ì…€ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

def get_daily_stock_prices(code, pages=10):
    """
    ì¢…ëª©ì½”ë“œ(code)ë¥¼ ë°›ì•„ ì¼ë³„ ì‹œì„¸ë¥¼ ê°€ì ¸ì™€ DataFrameìœ¼ë¡œ ë°˜í™˜.
    í˜¸ì¶œ URL: https://m.stock.naver.com/api/stock/{code}/price
    """
    url = f"https://m.stock.naver.com/api/stock/{code}/price"
    all_prices = []

    print(f"=== [{code}] ì‹œì„¸ ë°ì´í„° ìš”ì²­ ì¤‘... ===")

    for page in range(1, pages + 1):
        params = {"pageSize": 20, "page": page}
        try:
            response = requests.get(url, params=params, headers=HEADERS, timeout=5)
            response.raise_for_status()
            data = response.json()
            if data:
                all_prices.extend(data)
                print(f" -> {page}í˜ì´ì§€ ìˆ˜ì§‘ ì„±ê³µ ({len(data)}ê±´)")
            else:
                break
        except Exception as e:
            print(f"API ìš”ì²­ ì˜¤ë¥˜: {e}")
            break
        time.sleep(0.1)

    if not all_prices:
        return pd.DataFrame()

    df = pd.DataFrame(all_prices)
    rename_map = {
        'localTradedAt': 'ë‚ ì§œ',
        'closePrice': 'ì¢…ê°€',
        'compareToPreviousClosePrice': 'ì „ì¼ë¹„',
        'openPrice': 'ì‹œê°€',
        'highPrice': 'ê³ ê°€',
        'lowPrice': 'ì €ê°€',
        'accumulatedTradingVolume': 'ê±°ë˜ëŸ‰',
        'fluctuationsRatio': 'ë“±ë½ë¥ ',
    }
    available = [c for c in rename_map.keys() if c in df.columns]
    return df[available].rename(columns=rename_map)

# ==========================================
# 4. ì „ì²˜ë¦¬ / í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ / EDA
# ==========================================

def process_time_series(df_ts, date_col='ë‚ ì§œ', price_col='ì¢…ê°€', volume_col='ê±°ë˜ëŸ‰', ticker=None):
    """
    ë‹¨ì¼ ì¢…ëª©ì˜ ì¼ë³„ ì‹œê³„ì—´ DataFrameì„ ë°›ì•„ì„œ:
    - ë‚ ì§œ ì •ë¦¬, ê²°ì¸¡ ì²˜ë¦¬, ì´ìƒì¹˜ ì²˜ë¦¬
    - ì´ë™í‰ê· (MA5, MA20, MA60), ê±°ë˜ëŸ‰ ë³€í™”ìœ¨, ìˆ˜ìµë¥ (1/5/20), ë³€ë™ì„±(20ì¼), Drawdown
    - ì¶”ê°€ í…Œí¬ë‹ˆì»¬ ì§€í‘œ: RSI, MACD, Bollinger Band, Stochastic, volume ratio
    - íƒ€ê¹ƒ(ë‹¤ìŒë‚  ìˆ˜ìµë¥ , 5ì¼ ìˆ˜ìµë¥ ) ìƒì„±
    ë°˜í™˜: ì²˜ë¦¬ëœ DataFrame
    """
    df = df_ts.copy()

    # ë‚ ì§œ ì •ë¦¬
    if date_col in df.columns:
        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
        df = df.sort_values(by=date_col).reset_index(drop=True)

    # ìˆ«ìí˜• ë³€í™˜
    for c in [price_col, volume_col, 'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€']:
        if c in df.columns:
            df[c] = df[c].astype(str).str.replace(',', '').replace('nan', np.nan)
            df[c] = pd.to_numeric(df[c], errors='coerce')

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    if price_col in df.columns:
        df[price_col] = df[price_col].interpolate(method='linear')
        df[price_col] = df[price_col].fillna(method='ffill').fillna(method='bfill')

    if volume_col in df.columns:
        df[volume_col] = df[volume_col].fillna(0)

    if price_col in df.columns:
        df = df[df[price_col] > 0].copy()

    # ì´ë™í‰ê· 
    for w in [5, 20, 60]:
        if price_col in df.columns:
            df[f"MA{w}"] = df[price_col].rolling(window=w, min_periods=1).mean()

    # ê±°ë˜ëŸ‰ ë³€í™”ìœ¨
    if volume_col in df.columns:
        df['vol_change'] = df[volume_col].pct_change().replace([np.inf, -np.inf], np.nan)

    # ìˆ˜ìµë¥ 
    if price_col in df.columns:
        df['ret_1d'] = df[price_col].pct_change(1)
        df['ret_5d'] = df[price_col].pct_change(5)
        df['ret_20d'] = df[price_col].pct_change(20)

    # ë³€ë™ì„±
    if 'ret_1d' in df.columns:
        df['volatility_20d'] = df['ret_1d'].rolling(20).std()

    # Drawdown
    if price_col in df.columns:
        roll_max = df[price_col].rolling(window=60, min_periods=1).max()
        df['drawdown'] = df[price_col] / roll_max - 1

    # ====== ì¶”ê°€ í…Œí¬ë‹ˆì»¬ ì¸ë””ì¼€ì´í„° ======

    # RSI(14)
    if price_col in df.columns:
        delta = df[price_col].diff()
        gain = delta.clip(lower=0)
        loss = -delta.clip(upper=0)
        window = 14
        avg_gain = gain.rolling(window, min_periods=window).mean()
        avg_loss = loss.rolling(window, min_periods=window).mean()
        rs = avg_gain / avg_loss.replace(0, np.nan)
        df['RSI14'] = 100 - (100 / (1 + rs))
        df['RSI14'] = df['RSI14'].fillna(method='bfill')

    # MACD (12-26, signal 9)
    if price_col in df.columns:
        ema12 = df[price_col].ewm(span=12, adjust=False).mean()
        ema26 = df[price_col].ewm(span=26, adjust=False).mean()
        df['MACD'] = ema12 - ema26
        df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
        df['MACD_hist'] = df['MACD'] - df['MACD_signal']

    # Bollinger Band (20)
    if price_col in df.columns and 'MA20' in df.columns:
        std20 = df[price_col].rolling(window=20, min_periods=20).std()
        df['BB_upper'] = df['MA20'] + 2 * std20
        df['BB_lower'] = df['MA20'] - 2 * std20
        df['BB_width'] = (df['BB_upper'] - df['BB_lower']) / df['MA20']

    # Stochastic Oscillator (%K, %D)
    if price_col in df.columns and 'ê³ ê°€' in df.columns and 'ì €ê°€' in df.columns:
        low14 = df['ì €ê°€'].rolling(window=14, min_periods=14).min()
        high14 = df['ê³ ê°€'].rolling(window=14, min_periods=14).max()
        stoch_k = (df[price_col] - low14) / (high14 - low14)
        df['StochK'] = stoch_k
        df['StochD'] = df['StochK'].rolling(window=3, min_periods=3).mean()

    # Volume MA / Ratio
    if volume_col in df.columns:
        df['vol_ma5'] = df[volume_col].rolling(window=5, min_periods=1).mean()
        df['vol_ma20'] = df[volume_col].rolling(window=20, min_periods=1).mean()
        df['vol_ratio'] = df[volume_col] / df['vol_ma20'].replace(0, np.nan)

    # íƒ€ê¹ƒ ìƒì„±
    if 'ret_1d' in df.columns:
        df['target_ret_1d'] = df['ret_1d'].shift(-1)
    if 'ret_5d' in df.columns:
        df['target_ret_5d'] = df['ret_5d'].shift(-5)

    # ticker
    if ticker:
        df['ticker'] = ticker
    else:
        if 'ticker' not in df.columns:
            df['ticker'] = 'UNKNOWN'

    if date_col in df.columns:
        df = df.sort_values(by=date_col).reset_index(drop=True)

    return df

def eda_and_visualize(df, date_col='ë‚ ì§œ', price_col='ì¢…ê°€'):
    """
    ê°„ë‹¨í•œ EDA ì‹œê°í™”:
    - ê°€ê²© & ì´ë™í‰ê·  (plotly)
    - 1ì¼ ìˆ˜ìµë¥  ë¶„í¬/ë°•ìŠ¤í”Œë¡¯
    - ìˆ«ìí˜• ì»¬ëŸ¼ ìƒê´€ê´€ê³„ heatmap
    """
    numeric_df = df.select_dtypes(include=[np.number])

    # ê°€ê²© + ì´ë™í‰ê· 
    try:
        if price_col in df.columns:
            fig = go.Figure()
            x = df[date_col] if date_col in df.columns else df.index
            fig.add_trace(go.Scatter(x=x, y=df[price_col], mode='lines', name='Close'))
            for ma in ['MA5', 'MA20', 'MA60']:
                if ma in df.columns:
                    fig.add_trace(go.Scatter(x=x, y=df[ma], mode='lines', name=ma))
            fig.update_layout(title='Price & Moving Averages', xaxis_title='Date', yaxis_title='Price')
            fig.show()
    except Exception as e:
        print("Plotly ê°€ê²© ê·¸ë˜í”„ ìƒì„± ì¤‘ ì˜¤ë¥˜:", e)

    # 1ì¼ ìˆ˜ìµë¥  ë¶„í¬
    try:
        if 'ret_1d' in df.columns:
            plt.figure(figsize=(10, 4))
            sns.histplot(df['ret_1d'].dropna(), bins=100, kde=False)
            plt.title('1-day Return Distribution')
            plt.xlabel('ret_1d')
            plt.show()

            plt.figure(figsize=(8, 4))
            sns.boxplot(x=df['ret_1d'].dropna())
            plt.title('1-day Return Boxplot')
            plt.xlabel('ret_1d')
            plt.show()
    except Exception as e:
        print("ìˆ˜ìµë¥  ë¶„í¬/ë°•ìŠ¤í”Œë¡¯ ìƒì„± ì¤‘ ì˜¤ë¥˜:", e)

    # ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ
    try:
        if numeric_df.shape[1] > 1:
            plt.figure(figsize=(10, 8))
            sns.heatmap(numeric_df.corr(), cmap='coolwarm', center=0)
            plt.title('Correlation Heatmap (numeric only)')
            plt.show()
        else:
            print("Heatmap ìƒëµ â€” ìˆ«ìí˜• ì»¬ëŸ¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    except Exception as e:
        print("íˆíŠ¸ë§µ ìƒì„± ì¤‘ ì˜¤ë¥˜:", e)

def safe_save_csv(df, path):
    os.makedirs(os.path.dirname(path) or ".", exist_ok=True)
    df.to_csv(path, index=False)

def load_latest_processed(path="data/processed", pattern="merged_data_*.csv"):
    files = sorted(glob.glob(os.path.join(path, pattern)))
    if not files:
        raise FileNotFoundError("processed CSVê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    latest = files[-1]
    print("Loaded:", latest)
    return pd.read_csv(latest), latest

# ==========================================
# 5. ê¸°ë³¸ ì²´í¬/ë°±í…ŒìŠ¤íŠ¸ + ëª¨ë¸ë§
# ==========================================

def ensure_basic(df):
    rename_map = {
        'ì¼ê°„ìˆ˜ìµë¥ ': 'ret_1d',
        'ì£¼ê°„ìˆ˜ìµë¥ ': 'ret_5d',
        'ì›”ê°„ìˆ˜ìµë¥ ': 'ret_20d',
        'ë³€ë™ì„±_20': 'volatility_20d',
        'ê³ ì ëŒ€ë¹„í•˜ë½ë¥ ': 'drawdown',
        'ê±°ë˜ëŸ‰ë³€í™”ìœ¨': 'vol_change',
    }
    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})
    if 'ì¢…ê°€' not in df.columns or 'ret_1d' not in df.columns:
        raise KeyError("í•„ìˆ˜ ì»¬ëŸ¼(ì¢…ê°€, ret_1d)ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    return df

def backtest_series(df, signal_col='signal', price_col='ì¢…ê°€',
                    initial_capital=1_000_000, fee=0.0005, slippage=0.0002):
    df = df.reset_index(drop=True).copy()
    cash = initial_capital
    shares = 0.0
    nav = []
    for i in range(len(df) - 1):
        nav.append(cash + shares * df.loc[i, price_col])
        sig = int(df.loc[i, signal_col])
        nxt = df.loc[i + 1, price_col]
        if sig == 1 and cash > 0:
            amt = cash
            shares += amt * (1 - fee - slippage) / nxt
            cash = 0
        elif sig == 0 and shares > 0:
            cash += shares * nxt * (1 - fee - slippage)
            shares = 0
    nav.append(cash + shares * df.loc[len(df) - 1, price_col])
    return pd.Series(nav)

def perf_from_nav(nav, initial_capital=1_000_000):
    total = float(nav.iloc[-1] / initial_capital - 1)
    days = len(nav)
    years = days / 252 if days > 0 else 0
    cagr = (nav.iloc[-1] / initial_capital) ** (1 / years) - 1 if years > 0 else float('nan')
    mdd = float(((nav - nav.cummax()) / nav.cummax()).min())
    return {'total_return': total, 'CAGR': cagr, 'MDD': mdd}

def run_c3_pipeline_allmodels(df=None, features=None,
                              model_threshold=None,  # Noneì´ë©´ ìë™ íƒìƒ‰
                              initial_capital=1_000_000, fast=False):
    if df is None:
        df, path = load_latest_processed()
    df = ensure_basic(df)

    # ê¸°ë³¸ feature + ì‹ ê·œ ì¸ë””ì¼€ì´í„°ë“¤
    base_features = [
        'ì¢…ê°€', 'ì‹œê°€', 'ê³ ê°€', 'ì €ê°€', 'ê±°ë˜ëŸ‰',
        'MA5', 'MA20', 'MA60',
        'volatility_20d', 'drawdown', 'vol_change',
        'RSI14', 'MACD', 'MACD_signal', 'MACD_hist',
        'BB_width', 'StochK', 'StochD',
        'vol_ma5', 'vol_ma20', 'vol_ratio',
    ]
    forbidden = {'ret_1d', 'ret_5d', 'ret_20d', 'target_ret_1d', 'target_ret_5d', 'target'}
    feat_list = [c for c in base_features if c in df.columns and c not in forbidden]
    if features:
        feat_list = [c for c in features if c in df.columns and c not in forbidden]
    if not feat_list:
        raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ featureê°€ ì—†ìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # ìˆ«ìí˜•/ê²°ì¸¡ ì²˜ë¦¬
    df[feat_list] = df[feat_list].apply(pd.to_numeric, errors='coerce')
    df = df.dropna(subset=['ì¢…ê°€', 'ret_1d']).copy()
    df[feat_list] = df[feat_list].fillna(method='ffill').fillna(method='bfill').fillna(0)
    df['target'] = (df['ret_1d'] > 0).astype(int)

    # Train / Test ë¶„í• 
    split_idx = int(len(df) * 0.8)
    train = df.iloc[:split_idx]
    test = df.iloc[split_idx:].reset_index(drop=True)

    X_train, y_train = train[feat_list], train['target']
    X_test, y_test = test[feat_list], test['target']

    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)

    # class imbalance ë³´ì •
    pos_count = y_train.sum()
    neg_count = len(y_train) - pos_count
    if pos_count == 0:
        pos_weight = 1.0
    else:
        pos_weight = neg_count / pos_count

    rf_n = 50 if fast else 200
    xgb_n = 50 if fast else 200

    models = {
        'Logistic': LogisticRegression(max_iter=400, class_weight='balanced'),
        'RandomForest': RandomForestClassifier(
            n_estimators=rf_n,
            random_state=42,
            class_weight='balanced'
        ),
    }
    if _HAS_XGB:
        models['XGBoost'] = XGBClassifier(
            n_estimators=xgb_n,
            random_state=42,
            use_label_encoder=False,
            eval_metric='logloss',
            scale_pos_weight=pos_weight
        )

    perf = {}
    trained = {}

    # ====== ëª¨ë¸ í•™ìŠµ & í‰ê°€ ======
    for name, m in models.items():
        m.fit(X_train_s, y_train)
        pred = m.predict(X_test_s)
        try:
            proba = m.predict_proba(X_test_s)[:, 1]
        except Exception:
            proba = np.zeros(len(pred))
        try:
            auc_v = float(roc_auc_score(y_test, proba))
        except Exception:
            auc_v = float('nan')
        perf[name] = {
            'accuracy': float(accuracy_score(y_test, pred)),
            'f1': float(f1_score(y_test, pred)),
            'auc': auc_v,
        }
        trained[name] = m

    # ====== RandomForest ê¸°ì¤€ ì‹œê·¸ë„ ìƒì„± ======
    rf = trained.get('RandomForest', None)
    if rf is not None:
        proba_test = rf.predict_proba(X_test_s)[:, 1]

        # threshold ìë™ íƒìƒ‰ (train ë°ì´í„° ê¸°ì¤€)
        if model_threshold is None:
            proba_tr = rf.predict_proba(X_train_s)[:, 1]
            best_thr = 0.5
            best_f1 = -1.0
            for thr in np.linspace(0.4, 0.6, 21):
                pred_thr = (proba_tr > thr).astype(int)
                f1_thr = f1_score(y_train, pred_thr)
                if f1_thr > best_f1:
                    best_f1 = f1_thr
                    best_thr = thr
            model_threshold = best_thr
            print(f"[RF] ìë™ threshold ì„ íƒ: {model_threshold:.3f} (train F1={best_f1:.3f})")
        else:
            print(f"[RF] ì‚¬ìš©ì ì§€ì • threshold ì‚¬ìš©: {model_threshold:.3f}")

        test['proba'] = proba_test
        test['model_signal'] = (test['proba'] > model_threshold).astype(int)
    else:
        test['proba'] = 0.0
        test['model_signal'] = 0

    # ====== ë‹¨ìˆœ ë£° ì‹œê·¸ë„ (MA í¬ë¡œìŠ¤) ======
    if 'MA5' in test.columns and 'MA20' in test.columns:
        test['rule_signal'] = (test['MA5'] > test['MA20']).astype(int)
    else:
        test['rule_signal'] = 0

    # ====== ë°±í…ŒìŠ¤íŠ¸ ======
    nav_rule = backtest_series(test, signal_col='rule_signal',
                               price_col='ì¢…ê°€', initial_capital=initial_capital)
    nav_model = backtest_series(test, signal_col='model_signal',
                                price_col='ì¢…ê°€', initial_capital=initial_capital)
    nav_bh = (test['ì¢…ê°€'] / test['ì¢…ê°€'].iloc[0]) * initial_capital

    perf_rule = perf_from_nav(nav_rule, initial_capital)
    perf_model = perf_from_nav(nav_model, initial_capital)
    perf_bh = perf_from_nav(nav_bh.reset_index(drop=True), initial_capital)

    # ====== Feature Importance ======
    feat_imp = None
    if 'RandomForest' in trained:
        try:
            rf_imp = trained['RandomForest'].feature_importances_
            feat_imp = pd.DataFrame({'feature': feat_list, 'importance': rf_imp}) \
                         .sort_values('importance', ascending=False) \
                         .reset_index(drop=True)
        except Exception:
            feat_imp = None
    elif 'XGBoost' in trained:
        try:
            x_imp = trained['XGBoost'].feature_importances_
            feat_imp = pd.DataFrame({'feature': feat_list, 'importance': x_imp}) \
                         .sort_values('importance', ascending=False) \
                         .reset_index(drop=True)
        except Exception:
            feat_imp = None

    if feat_imp is not None and not feat_imp.empty:
        top3 = feat_imp.head(3).copy().reset_index(drop=True)
        print("\n=== Feature Importance (Top 3) ===")
        print(top3.to_string(index=False))
        os.makedirs('output', exist_ok=True)
        top3.to_csv('output/feature_importance_top3.csv', index=False)
    else:
        print("\n(Feature importance not available)")

    # ====== ê²°ê³¼ ì €ì¥ ======
    os.makedirs('output', exist_ok=True)
    safe_save_csv(test, 'output/strategy_signals.csv')
    summary = {
        'models': perf,
        'rule_perf': perf_rule,
        'model_perf': perf_model,
        'bh_perf': perf_bh,
        'model_threshold': model_threshold,
    }
    with open('output/c3_summary.json', 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)

    print("\n=== ëª¨ë¸ ì„±ëŠ¥ ===")
    for k, v in perf.items():
        print(f"{k}: acc={v['accuracy']:.4f}, f1={v['f1']:.4f}, auc={v['auc']:.4f}")
    print("\n=== ì „ëµ ì„±ê³¼ ===")
    print(f"Rule   : total_return={perf_rule['total_return']:.4f}, CAGR={perf_rule['CAGR']:.4f}, MDD={perf_rule['MDD']:.4f}")
    print(f"Model  : total_return={perf_model['total_return']:.4f}, CAGR={perf_model['CAGR']:.4f}, MDD={perf_model['MDD']:.4f}")
    print(f"BuyHold: total_return={perf_bh['total_return']:.4f}, CAGR={perf_bh['CAGR']:.4f}, MDD={perf_bh['MDD']:.4f}")

    return {
        'trained': trained,
        'perf': perf,
        'summary': summary,
        'signals': test,
        'nav_rule': nav_rule,
        'nav_model': nav_model,
        'nav_bh': nav_bh,
        'feat_imp': feat_imp,
    }

def run_c3_pipeline(df=None, features=None,
                    model_threshold=None,  # Noneì´ë©´ ìë™ìœ¼ë¡œ ìµœì  threshold íƒìƒ‰
                    initial_capital=1_000_000, fast=False):
    """
    ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ì„ ìœ„í•´ ë‚¨ê¸´ ë˜í¼ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    ë‚´ë¶€ì ìœ¼ë¡œ run_c3_pipeline_allmodels ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    return run_c3_pipeline_allmodels(
        df=df,
        features=features,
        model_threshold=model_threshold,
        initial_capital=initial_capital,
        fast=fast,
    )

# ==========================================
# 6. í†µí•© ì‹¤í–‰ main()
# ==========================================

def main():
    print("\n[1] ê±°ë˜ëŸ‰ ìƒìœ„ ì£¼ì‹ ëª©ë¡ (ìƒìœ„ 5ê°œ)")
    try:
        df_top = get_top_stocks_data()
        if not df_top.empty:
            print(df_top[['ì¢…ëª©ëª…', 'ì¢…ëª©ì½”ë“œ', 'í˜„ì¬ê°€', 'ë“±ë½ë¥ ', 'ê±°ë˜ëŸ‰']].head(5))
        else:
            print("  ê±°ë˜ëŸ‰ ìƒìœ„ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print("  ê±°ë˜ëŸ‰ ìƒìœ„ ì¡°íšŒ ì˜¤ë¥˜:", e)

    print("\n[2] KOSPI ì •ë³´")
    try:
        kospi_data = get_kospi_info()
        print_kospi_formatted(kospi_data)
    except Exception as e:
        print("  KOSPI ì¡°íšŒ ì˜¤ë¥˜:", e)

    print("\n[3] ë¶„ì„í•  ì¢…ëª© ì„ íƒ")
    user_in = input("ë¶„ì„í•  ì¢…ëª©ëª…(ì˜ˆ: ì‚¼ì„±ì „ì) ë˜ëŠ” 6ìë¦¬ ì¢…ëª©ì½”ë“œ, ë˜ëŠ” AUTOë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()

    if user_in.upper() == "AUTO":
        df_top = get_top_stocks_data()
        if df_top.empty:
            print("AUTO ì‹¤íŒ¨: ê±°ë˜ëŸ‰ ìƒìœ„ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return
        target_name = df_top.iloc[0]['ì¢…ëª©ëª…']
        code_for_fetch = df_top.iloc[0]['ì¢…ëª©ì½”ë“œ']
        print(f"AUTO ì„ íƒ: ê±°ë˜ëŸ‰ 1ìœ„ ì¢…ëª© -> {target_name} ({code_for_fetch})")
    else:
        if re.match(r'^\d{6}$', user_in):
            code_for_fetch = user_in
            target_name = user_in
        else:
            target_name = user_in
            code_for_fetch = get_code_from_excel(target_name)
            if not code_for_fetch:
                print("ì¢…ëª©ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return

    print(f"\n[4] ì‹œì„¸ ë°ì´í„° ìˆ˜ì§‘: {target_name} ({code_for_fetch})")
    df_price = get_daily_stock_prices(code_for_fetch, pages=10)
    if df_price.empty:
        print("ì‹œì„¸ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    print("\n[5] ì „ì²˜ë¦¬ ë° í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§")
    processed = process_time_series(
        df_price,
        date_col='ë‚ ì§œ',
        price_col='ì¢…ê°€',
        volume_col='ê±°ë˜ëŸ‰',
        ticker=target_name
    )
    processed = processed.sort_values('ë‚ ì§œ').reset_index(drop=True)
    if 'ì¢…ê°€' in processed.columns:
        processed['ì¢…ê°€'] = processed['ì¢…ê°€'].interpolate().ffill().bfill()
    if 'ê±°ë˜ëŸ‰' in processed.columns:
        processed['ê±°ë˜ëŸ‰'] = processed['ê±°ë˜ëŸ‰'].fillna(0)

    os.makedirs("data/processed", exist_ok=True)
    out_path = os.path.join("data/processed", f"merged_data_{code_for_fetch}.csv")
    processed.to_csv(out_path, index=False)
    print(f"ì „ì²˜ë¦¬ ë°ì´í„° ì €ì¥: {out_path}")

    print("\n[6] EDA ì‹œê°í™” (ì„ íƒì )")
    try:
        eda_and_visualize(processed, date_col='ë‚ ì§œ', price_col='ì¢…ê°€')
    except Exception as e:
        print("EDA ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:", e)

    print("\n[7] ëª¨ë¸ë§ ë° ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    try:
        _ = run_c3_pipeline(
            df=processed,
            features=None,
            model_threshold=None,   # ìë™ìœ¼ë¡œ ìµœì  threshold íƒìƒ‰
            initial_capital=1_000_000,
            fast=False
        )
        print("\nëª¨ë¸ë§/ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ.")
    except Exception as e:
        print("ëª¨ë¸/ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜:", e)

    print("\ní”„ë¡œì„¸ìŠ¤ ì™„ë£Œ.")

if __name__ == "__main__":
    main()
